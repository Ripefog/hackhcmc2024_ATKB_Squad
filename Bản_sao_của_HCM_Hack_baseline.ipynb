{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ripefog/hackhcmc2024_ATKB_Squad/blob/main/B%E1%BA%A3n_sao_c%E1%BB%A7a_HCM_Hack_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqIfydXthYE8",
        "outputId": "084b88cd-2cc6-4c03-99b2-a2d714ddba1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-hISmbzmhuJaySCv4g0fn95pU1G9GtWa\n",
            "To: /content/test_data_1.jpg\n",
            "\r  0% 0.00/835k [00:00<?, ?B/s]\r100% 835k/835k [00:00<00:00, 41.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1-hISmbzmhuJaySCv4g0fn95pU1G9GtWa\n",
        "!pip install -q easyocr\n",
        "!pip install groq\n",
        "!pip install -q streamlit\n",
        "!npm install localtunnel\n",
        "!pip install pymongo pillow\n",
        "!pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq-9BfjzH0z7",
        "outputId": "ad88fbd8-60cb-4a8b-caa7-a7fc4ee52cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from groq import Groq\n",
        "import requests\n",
        "import json\n",
        "import streamlit as st\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline\n",
        "import glob\n",
        "import torch\n",
        "from pymongo import MongoClient\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5h5qx3Yubr"
      },
      "source": [
        "# Simple streamlit app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93fpu0_XdFYE"
      },
      "outputs": [],
      "source": [
        "# MongoDB Atlas connection\n",
        "client = MongoClient(\"mongodb+srv://cakoipro123456:khuong1182004@cluster0.auqviui.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client['image_analysis_db']\n",
        "history_collection = db['analysis_history']\n",
        "\n",
        "# Function to load image icons from URL\n",
        "def load_image_url(url):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code != 200:\n",
        "        return None\n",
        "    return Image.open(response.raw)\n",
        "\n",
        "# Load image icons\n",
        "upload_icon = load_image_url(\"https://example.com/path_to_upload_icon.png\")\n",
        "processing_icon = load_image_url(\"https://example.com/path_to_processing_icon.png\")\n",
        "analysis_icon = load_image_url(\"https://example.com/path_to_analysis_icon.png\")\n",
        "\n",
        "# Initialize the OCR reader\n",
        "ocr_reader = easyocr.Reader([\"en\", \"vi\"])\n",
        "\n",
        "# Functions for image processing\n",
        "def get_image_caption(image):\n",
        "    caption_pipeline = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
        "    return caption_pipeline(image)[0]['generated_text']\n",
        "\n",
        "def perform_ocr(image):\n",
        "    result = ocr_reader.readtext(np.array(image))\n",
        "    return result\n",
        "\n",
        "def analyze_image_information(image_description, ocr_results):\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following image information and provide insights based on the criteria given below:\n",
        "\n",
        "    Image Description:\n",
        "    {image_description}\n",
        "\n",
        "    OCR Results:\n",
        "    {ocr_results}\n",
        "\n",
        "    Criteria:\n",
        "    1. Brand Logos: Identify any brand logos mentioned in the description or OCR results:  Heineken, Tiger, Bia Việt, Larue, Bivina, Edelweiss and Strongbow and other competitor or non-competitor brands\n",
        "    2. Products: Mention any products such as beer kegs and bottles.\n",
        "    3. Customers: Describe the number of customers, their activities, and emotions.\n",
        "    4. Promotional Materials: Identify any posters, banners, and billboards.\n",
        "    5. Setup Context: Determine the scene context (e.g., bar, restaurant, grocery store, or supermarket).\n",
        "    6. Evaluate the success of the event.\n",
        "    7. Follow up with marketing staff.\n",
        "    8. Evaluate the level of presence in the store.\n",
        "\n",
        "    Insights:\n",
        "    \"\"\"\n",
        "    client = Groq(api_key=\"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\")\n",
        "    data = {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "    chat_completion = client.chat.completions.create(**data)\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "def convert_image_to_base64(image):\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"JPEG\")\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "    return img_str\n",
        "\n",
        "def extract_first_frame(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        cap.release()\n",
        "        return image\n",
        "    cap.release()\n",
        "    return None\n",
        "\n",
        "# Functions for video processing\n",
        "def extract_frames(video_path, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        cv2.imwrite(os.path.join(output_folder, f\"frame{count:04d}.jpg\"), frame)\n",
        "        count += 1\n",
        "    cap.release()\n",
        "    print(f\"Extracted {count} frames.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(image, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "def generate_video_description(frames_folder):\n",
        "    frame_paths = sorted(glob.glob(os.path.join(frames_folder, '*.jpg')))\n",
        "    descriptions = []\n",
        "    for frame_path in frame_paths:\n",
        "        caption = generate_caption(frame_path)\n",
        "        descriptions.append(caption)\n",
        "    detailed_description = \" \".join(descriptions)\n",
        "    return detailed_description\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "def summarize_text(text, max_length=130, min_length=30):\n",
        "    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']\n",
        "    return summary\n",
        "\n",
        "def extract_text_from_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    extracted_text = []\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        result = ocr_reader.readtext(frame)\n",
        "        for (bbox, text, prob) in result:\n",
        "            extracted_text.append(text)\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return extracted_text\n",
        "\n",
        "def analyze_video_information(video_description, video_ocr_results):\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following image information and provide insights based on the criteria given below:\n",
        "\n",
        "    Image Description:\n",
        "    {image_description}\n",
        "\n",
        "    OCR Results:\n",
        "    {ocr_results}\n",
        "\n",
        "    Criteria:\n",
        "    1. Brand Logos: Identify any brand logos mentioned in the description or OCR results:  Heineken, Tiger, Bia Việt, Larue, Bivina, Edelweiss and Strongbow.\n",
        "    2. Products: Mention any products such as beer kegs and bottles.\n",
        "    3. Customers: Describe the number of customers, their activities, and emotions.\n",
        "    4. Promotional Materials: Identify any posters, banners, and billboards.\n",
        "    5. Setup Context: Determine the scene context (e.g., bar, restaurant, grocery store, or supermarket).\n",
        "    6. Evaluate the success of the event.\n",
        "    7. Follow up with marketing staff.\n",
        "    8. Evaluate the level of presence in the store.\n",
        "\n",
        "    Insights:\n",
        "    \"\"\"\n",
        "    client = Groq(api_key=\"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\")\n",
        "    data = {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "    chat_completion = client.chat.completions.create(**data)\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "# Streamlit app\n",
        "st.set_page_config(layout=\"wide\", page_icon=\"📷\", page_title=\"Image and Video Analysis App\")\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "    .main {\n",
        "        background-color: black;\n",
        "    }\n",
        "    .stButton button {\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "    .stHeader, .stSubheader, .stMarkdown {\n",
        "        color: white;\n",
        "        background-color: black;\n",
        "    }\n",
        "    .title {\n",
        "        color: #FFA500;\n",
        "        font-size: 24px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .description {\n",
        "        color: #00FF00;\n",
        "        font-size: 18px;\n",
        "    }\n",
        "    .analysis {\n",
        "        color: #1E90FF;\n",
        "        font-size: 18px;\n",
        "    }\n",
        "    .delete-button {\n",
        "        background-color: #FF4500;\n",
        "        color: white;\n",
        "    }\n",
        "    .sidebar .sidebar-content {\n",
        "        background-color: #2E2E2E;\n",
        "    }\n",
        "    .sidebar .sidebar-content .nav-item {\n",
        "        color: #FFFFFF;\n",
        "        font-size: 20px;\n",
        "    }\n",
        "    .sidebar .sidebar-content .nav-item:hover {\n",
        "        background-color: #1E1E1E;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.sidebar.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "    .sidebar .sidebar-content {\n",
        "        background-color: #2E2E2E;\n",
        "    }\n",
        "    .sidebar .sidebar-content .nav-item {\n",
        "        color: #FFFFFF;\n",
        "        font-size: 20px;\n",
        "        padding: 10px;\n",
        "        border-radius: 5px;\n",
        "    }\n",
        "    .sidebar .sidebar-content .nav-item:hover {\n",
        "        background-color: #1E1E1E;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.sidebar.title(\"Home\")\n",
        "app_mode = st.sidebar.selectbox(\"Choose the app mode\", [\"Main\", \"History\"], format_func=lambda x: \"🏠 Main\" if x == \"Main\" else \"📜 History\")\n",
        "\n",
        "if app_mode == \"Main\":\n",
        "    st.markdown(\"<div class='title'>📷 Image and Video Analysis App</div>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"<div class='description'>Analyze images and videos to get detailed insights using AI models.</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    col1, col2, col3 = st.columns([1, 2, 2])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"📤 Upload Image or Video\")\n",
        "        if upload_icon:\n",
        "            st.image(upload_icon, width=150)\n",
        "        uploaded_file = st.file_uploader(\"Choose an image or video file\", type=[\"jpg\", \"jpeg\", \"png\", \"mp4\", \"avi\", \"mov\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        file_type = uploaded_file.type.split('/')[0]\n",
        "\n",
        "        if file_type == 'image':\n",
        "            with col2:\n",
        "                st.header(\"🔍 Description\")\n",
        "                image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "\n",
        "                if processing_icon:\n",
        "                    st.image(processing_icon, width=100)\n",
        "\n",
        "                st.subheader(\"Image Description\")\n",
        "                image_description = get_image_caption(image)\n",
        "                st.markdown(f\"<div class='description'>{image_description}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "                ocr_result = perform_ocr(image)\n",
        "\n",
        "                image_np = np.array(image)\n",
        "                boxes = [line[0] for line in ocr_result]\n",
        "                texts = [line[1] for line in ocr_result]\n",
        "\n",
        "                for box, text in zip(boxes, texts):\n",
        "                    top_left = (int(box[0][0]), int(box[0][1]))\n",
        "                    bottom_right = (int(box[2][0]), int(box[2][1]))\n",
        "                    cv2.rectangle(image_np, top_left, bottom_right, (0, 255, 0), 2)\n",
        "                    cv2.putText(image_np, text, top_left, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
        "\n",
        "                st.image(image_np, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "            with col3:\n",
        "                st.header(\"📊 Analysis\")\n",
        "                if analysis_icon:\n",
        "                    st.image(analysis_icon, width=100)\n",
        "\n",
        "                ocr_results = ' '.join([line[1] for line in ocr_result])\n",
        "                analysis = analyze_image_information(image_description, ocr_results)\n",
        "                st.markdown(f\"<div class='analysis'>{analysis}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "                # Save to history\n",
        "                img_base64 = convert_image_to_base64(image)\n",
        "                history_collection.insert_one({\n",
        "                    \"type\": \"image\",\n",
        "                    \"description\": image_description,\n",
        "                    \"ocr\": ocr_results,\n",
        "                    \"analysis\": analysis,\n",
        "                    \"image_base64\": img_base64\n",
        "                })\n",
        "\n",
        "        elif file_type == 'video':\n",
        "            video_path = os.path.join(\".\", uploaded_file.name)\n",
        "            if not os.path.exists(\"temp\"):\n",
        "                os.makedirs(\"temp\")\n",
        "            with open(video_path, \"wb\") as f:\n",
        "                f.write(uploaded_file.getbuffer())\n",
        "\n",
        "            with col2:\n",
        "                st.header(\"🔍 Description\")\n",
        "                st.video(video_path, format=\"video/mp4\")\n",
        "\n",
        "                if processing_icon:\n",
        "                    st.image(processing_icon, width=100)\n",
        "\n",
        "                st.subheader(\"Video Description\")\n",
        "\n",
        "                first_frame = extract_first_frame(video_path)\n",
        "                if first_frame:\n",
        "                    st.image(first_frame, caption='First Frame of Video', use_column_width=True)\n",
        "                    image_description = get_image_caption(first_frame)\n",
        "                    st.markdown(f\"<div class='description'>{image_description}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "                frames_folder = 'frames'\n",
        "                extract_frames(video_path, frames_folder)\n",
        "\n",
        "                st.write(\"Generating video description...\")\n",
        "                detailed_description = generate_video_description(frames_folder)\n",
        "\n",
        "                st.write(\"Summarizing video description...\")\n",
        "                summary = summarize_text(detailed_description, max_length=150, min_length=50)\n",
        "                st.write(summary)\n",
        "\n",
        "                video_ocr_texts = extract_text_from_video(video_path)\n",
        "\n",
        "            with col3:\n",
        "                st.header(\"📊 Analysis\")\n",
        "                if analysis_icon:\n",
        "                    st.image(analysis_icon, width=100)\n",
        "\n",
        "                video_ocr_results = ' '.join(video_ocr_texts)\n",
        "                analysis = analyze_video_information(summary, video_ocr_results)\n",
        "                st.markdown(f\"<div class='analysis'>{analysis}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "                # Save to history\n",
        "                img_base64 = convert_image_to_base64(first_frame)\n",
        "                history_collection.insert_one({\n",
        "                    \"type\": \"video\",\n",
        "                    \"description\": summary,\n",
        "                    \"ocr\": video_ocr_texts,\n",
        "                    \"analysis\": analysis,\n",
        "                    \"image_base64\": img_base64\n",
        "                })\n",
        "\n",
        "elif app_mode == \"History\":\n",
        "    st.title(\"📜 Analysis History\")\n",
        "    st.markdown(\"### View the history of analyzed images and videos.\")\n",
        "\n",
        "    # Fetch history from MongoDB\n",
        "    history_items = list(history_collection.find().sort(\"_id\", -1))\n",
        "\n",
        "    for item in history_items:\n",
        "        st.markdown(f\"<div class='title'>Type: {item['type'].capitalize()}</div>\", unsafe_allow_html=True)\n",
        "        st.markdown(f\"<div class='description'>Image/Video Description:</div>\", unsafe_allow_html=True)\n",
        "        st.write(item['description'])\n",
        "        st.markdown(f\"<div class='analysis'>Analysis:</div>\", unsafe_allow_html=True)\n",
        "        st.write(item['analysis'])\n",
        "\n",
        "        if item['type'] == 'image' or item['type'] == 'video':\n",
        "            image_data = base64.b64decode(item['image_base64'])\n",
        "            image = Image.open(BytesIO(image_data))\n",
        "            st.image(image, caption='Analyzed Image/Video Frame')\n",
        "\n",
        "        st.write(\"---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_G9diQ6diLp"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfjSWnHWeD88",
        "outputId": "cce91fa9-4eca-4f38-c4b7-1f4e87728030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.145.1.14\n"
          ]
        }
      ],
      "source": [
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASeQp88VdxKJ",
        "outputId": "7ae3379c-6cc2-492b-da72-78cc2513dcc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.651s\n",
            "your url is: https://metal-friends-shine.loca.lt\n",
            "/root/.npm/_npx/4468/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:42355 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/4468/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SFE98QSGlIA2",
        "0u_4H5MKahNE"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}